\section{Introduction}
Update 3D model
how modules are connected etc

\section{Skyline detection}
This section describes how the skyline of an image is detected. A skyline
seperates a building from the sky and is used as an indicator of the building contour.
\\
Some previous work on skyline detection is done.
\cite{9} yields a good introduction of different skyline detection techiques.
In \cite{1}, a column based approach is used. This method is used in my implementation.
\\
The skyline detector works as follows.
First the image is preprocessed for the skyline detector algorithm.
The contrast of the image is maximized. Then the image undertakes a Gaussian blur.  On this image a
\textit{sobel} edge detector with a manual threshold is applied.
The result is feed to the skyline detector.
\\
The Skyline Detector uses an assumption: the first sharp edge (seen
from top to bottom) is always a skyline/building edge. The algorithm works as
follows: The value of a pixel in a column is evaluated. Iterating from top to
bottom, the system takes the first sharp edge (a pixel that is above a certain
threshold) and classifies this as a skyline pixel.  This is done for every
column in the edge image. The result is a set of coordinates of length $W$,
where $W$ is the width of the image, that represent the skyline.
\\
The Skyline detectior has an accuracy of (ABOUT) 90% (TODO CHECK THIS PERCENTAGE) 
In some cases outliers are detected, these are often a streetlight or a tree. The outliers are
filtered in the next step.

\section{}
motivation
(dis)advantages

motivation:
"To update the 3D model at the right place we need to know for every pixel 
which wall it most likely presents.  

\section{Skyline in 3D as a contour of the building}
The 3D building contour is necessary to update the sparse 3D model of the buliding.
This section describes how the 2D images are used to get the 3D contour of the
building. This is done in several distinct steps.  

\subsection{Project to 3D space}
Every 2D pixel of an input image presents a 3D point in space. Because no
information is known about the distance from the point to the camera, it
presents an infinite line of possible points in space.


This line is spanned by two known coordinates:
\begin{itemize}
\item The camera center, for the first camera $[0 0 0]\transpose$, the second %TODOOOOO
\item $K'p$, where $K$ is the Calibration matrix of the camera and $p$ is the homogeneous pixel coordinate.
\end{itemize}


\textbf{Intersect with walls of building}
To know which part of the building the pixel presents, the building is divided into different walls.
Every wall of the building spans a plane. Intersections are calculated between the line from the previous section and these planes.
The most propable intersection, the wall that is most likely responsable for the pixel, is calculated in the next.

\subsection{Select the right wall}
To find the right wall, the projected pixel must lie either
1) On the wall (inside the polygonal representation of the wall)
or
2) On a small distance from the wall

The first is calculated using an inpolygon algorithm.
The later is calculated as follows:
\\
First the distances from the intersection to all wall sides are calculated. For every wall the minimum of the four wall sides is used as its intersection point wall distance.
The wall with the smalles distance is the one that most likely presents the pixel. If there are two (or even more) walls that succeded the inpolygon test then the wall closest to the camera is selected.

\subsection{calculating the ISP wall distance}
A wall consists of four corner points. Two cornerpoints connect a line segment which represents a side of a wall. There are four line segments.

The ISP is projected on all four lines that are spanned by the line segments.
If the projected ISP lies between the two corner points (on the line segment) then the distance from the ISP to the projected ISP is returned.
If it lies outside the two corner points the euclidean distance to the closest cornerpoint is returned.

[I can explain how I did some clever dot product tricks but I think that is to much detail right?]


\section{Update 3D model}


\section{Citations}
[1] Castano, Automatic detection of dust devils and clouds on Mars
[9] Cozman, Outdoor visual position estimation for planetary rovers.
