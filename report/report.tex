\section{Skyline detection}
\cite{9} yields a good introduction af the different applied skyline detection
techiques.

In \cite{1}, a column based approach is used. This method is suitable for our
application.

First the contrast of the image is maximized, for now this is done by hand with
GIMP.  Then the image undertakes a Gaussian blur.  On this image a
\textit{sobel} edge detector with a manual threshold is applied.
The result is feed to the Skyline Detector.

The Skyline Detector uses an assumption: the first sharp edge (seen from top to
bottom) is always a skyline/building edge.  It works as follows:
Every column (width:1px) of the edge images is analysed. The value of a pixel
in a column is checked from top to bottom. The system classifies the first
pixel that is above a certain threshold as a skyline pixel.

[1] Castano, Automatic detection of dust devils and clouds on Mars
[9] Cozman, Outdoor visual position estimation for planetary rovers.



\section{}
motivation
(dis)advantages

motivation:
"To update the 3D model at the right place we need to know for every pixel 
which wall it most likely presents.  

\section{Project pixel in 3D space}
Every 2D pixel of an input image present a 3D point in space. Because no
information is known about the distance from the point to the camera, it
presents an infinite line of possible points in space.


This line is spanned by two known coordinates:
\begin{itemize}
\item The camera center, for the first camera $[0 0 0]\transpose$, the second %TODOOOOO
\item $K'p$, where $K$ is the Calibration matrix of the camera and $p$ is the homogeneous pixel coordinate.
\end{itemize}


\textbf{Intersect with walls of building}
To know which part of the building the pixel presents, the building is divided into different walls.
Every wall of the building spans a plane. Intersections are calculated between the line from the previous section and these planes.
The most propable intersection, the wall that is most likely responsable for the pixel, is calculated in the next.

\subsection{Select the right wall}
To find the right wall, the projected pixel must lie either
1) On the wall (inside the polygonal representation of the wall)
or
2) On a small distance from the wall

The first is calculated using an inpolygon algorithm.
The later is calculated as follows:
\\
First the distances from the intersection to all wall sides are calculated. For every wall the minimum of the four wall sides is used as its intersection point wall distance.
The wall with the smalles distance is the one that most likely presents the pixel. If there are two (or even more) walls that succeded the inpolygon test then the wall closest to the camera is selected.

\subsection{calculating the ISP wall distance}
A wall consists of four corner points. Two cornerpoints connect a line segment which represents a side of a wall. There are four line segments.

The ISP is projected on all four lines that are spanned by the line segments.
If the projected ISP lies between the two corner points (on the line segment) then the distance from the ISP to the projected ISP is returned.
If it lies outside the two corner points the euclidean distance to the closest cornerpoint is returned.

[I can explain how I did some clever dot product tricks but I think that is to much detail right?]


