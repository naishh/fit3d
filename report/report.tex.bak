\documentclass[10pt]{article}
\title{\sc Optimizing 3D models from 2D images}

\author{T. Kostelijk\\mailtjerk@gmail.com}

\date{December 16, 2010}

\begin{document}

\maketitle
\begin{abstract}
Here comes the abstract
\end{abstract}

\section{Introduction}
% TODO Heerlijk de todos zijn niet leesbaar ff ander kleurtje geven ouwe, syntax=tex configgen in vim

\section{Skyline detection}
% TODO MOTIVATION 
This section describes how the skyline of an image is detected. A skyline
separates a building from the sky and is used as an indicator of the building contour.
\\
% It is interesting to denote that the skyline detector a stand alone method and
% can be optimized individually without any knowledge of the other parts of the
% project.

Some previous work on skyline detection is done.\\
$[9]$ yields a good introduction of different skyline detection techniques.

A comparison is done of the different skyline techniques as described in $[9]$
and $[1]$ is most suitable as a basis for the purpose of this project.  This
method is used as an inspiration. A custom algorithm is made. First
the original method is explained. Then the custom algorithm with respect to the
orignal algorithm is explained.

The skyline detection algorithm as described in $[1]$ analyzes every column of
the image separately.  The smoothed intensity gradient is calculated from top
to bottom.  The system takes the first pixel with gradient higher then a threshold to be
classified as a skyline element.  This is done for every column in the smoothed
intensity gradient image. The result is a set of coordinates of length $W$,
where $W$ is the width of the image, that represent the skyline.
\textit{Should I elaborate (with a footnote?) on the smoothed
intensity gradient or could I assume this as common knowledge?}. 

Taking the smoothed intensity gradient is the most basic method of edge detection
and has a disadvantage. The method will not be robust to more vague edges.
Instead of the smoothed intensity gradient in this thesis a smoothed edge intensity image is
used.  A practical study is done on the different Matlab build in edge
detection techniques. The Sobel edge detector came with the most promising
results.  Details on this study lie without the bound of this thesis.\\

As a purpose of making the algorithm more precise, two other preprocessing
steps are introduced. First the contrast of the image is increased, this makes
sharp edges stand out more.  Secondly the image undertakes a Gaussian blur,
this removes a large part of the noise.

The system has no several parameters which has to be set manualy by the user:
\begin{itemize}
\item contrast parameter, 
\item intensity (window size) of Gaussian blur,
\item Sobel edge detetor threshold
\item column based inlier threshold
\end{itemize}
\textit{Should I write down what parameter values I used or is this of too much
detail}

(Automatic parameter estimation based on the image would be interesting future
work but lies without the scope of this research.)

The column based approach from $[1]$ seem to be very useful and is therefor
used as described above but on the preprocesed image.

Some results from the Floriande dataset:
% TODO Results images
% TODO make UML scheme skyline -> 3d -> etc.
\\
The system assumes that the first sharp edge (seen from top to bottom) is
always a skyline/building edge. This gives raise to some outliers, these are
for example a streetlight or a tree. The outliers are removedin as described in
the next section.  The Skyline detector without outlier removal has an
accuracy of (ABOUT) 90 \% (TODO CHECK THIS PERCENTAGE) 


\section{Skyline in 3D as a contour of the building}
The 3D building contour is used to update the sparse 3D model of the building.
This section describes how the 2D images are used to get the 3D contour of the
building. This is done in several distinct steps.  

\subsection{Project to 3D space}
Every 2D pixel of an input image presents a 3D point in space. No
information is known about the distance from the 3D point to the camera.
Therefore the algorithm starts with an infinite line of possible points in space.
This line is spanned by two known coordinates:\\
\begin{itemize}
	\item The camera center (camera centers are annotated for every image)
	\item $K'p$, where $K$ is the Calibration matrix of the camera and $p$ is the homogeneous pixel coordinate.
\end{itemize}

\subsection{Intersect with building}
A top-view image (source:Google maps) is used to create a rough indication of the building. The height of the building is estimated.\\
To know which part of the building the pixel presents, the building is divided into different walls.  Every wall of the building spans a plane. Intersections are calculated between the line from the previous section and these planes.\\
\\
The intersections are used to determine the wall that is has the largest probability of being responsible for the pixel. 
If a wall represents that pixel, the intersection (projected pixel) must lie either\\
\textbf{1)} On the wall (inside the polygonal representation of the wall)
\\
or
\\
\textbf{2)} On a small distance from the wall, this is treated as an inlier because the 3D model is sparse and the height of the building is unknown.
\\
The first is calculated using an in-polygon algorithm. The later is calculated as follows:
\\
First the distances from the intersection to four wall sides are calculated. For every wall the minimum distance is stored. The wall with the smallest distance is the one that most likely presents the pixel. If there are two (or even more) walls that succeeded the in-polygon test then the nearest wall (closest to the camera center) is selected. How the distance measure is calculated can be read in the next section.

\subsection{Calculate the intersection point - wall distance}
A wall consists of four corner points. Some corner-point pairs connect a line segment which represents a side of a wall. There are four line segments.\\
The intersection point (ISP) is projected orthogonally on all four lines that
are spanned by the line segments.  If the projected ISP lies between the two
corner points (on the line segment) then the distance from the ISP to the
projected ISP is returned.  If it lies outside the two corner points the
Euclidean distance to the closest corner-point is returned.

[I can explain how I did some clever dot product tricks but I think that is to much detail right?]


\section{Update 3D model}


\section{References}
\begin{itemize}
\item $[1]$ Castano, Automatic detection of dust devils and clouds on Mars.
\item $[9]$ Cozman, Outdoor visual position estimation for planetary rovers.
\end{itemize}

\end{document}
